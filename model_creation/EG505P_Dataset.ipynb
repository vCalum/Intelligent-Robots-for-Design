{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1P-u5ouF0YaxRNtLSThGcD-8TJrNx5U1Q",
      "authorship_tag": "ABX9TyPLstyienfiPt2PCfZth2XU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vCalum/Intelligent-Robots-for-Design/blob/main/EG505P_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trianing dataset for neural network"
      ],
      "metadata": {
        "id": "BrQID2y4pmU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhzf5q_abOMK",
        "outputId": "38de9816-1f58-45b3-84d8-7594ee0bac13"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "data_path='/content/drive/MyDrive/EG505P/train_data'\n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "\n",
        "label_dict = {} #empty dictionary\n",
        "cat_dict = {}\n",
        "\n",
        "for i in range(len(categories)):\n",
        "    label_dict[categories[i]]=labels[i]\n",
        "\n",
        "for i in range(len(categories)):\n",
        "    cat_dict[labels[i]]=categories[i]\n",
        "\n",
        "print(label_dict)\n",
        "print(cat_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-OQdR6F5Vw9",
        "outputId": "060ebb70-f6b0-4969-bc33-2105b2dace1c",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'right': 0, 'forward': 1, 'left': 2}\n",
            "{0: 'right', 1: 'forward', 2: 'left'}\n",
            "['right', 'forward', 'left']\n",
            "[0, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dict_file = open(\"/content/drive/MyDrive/EG505P/ai_car.pkl\", \"wb\")\n",
        "pickle.dump(cat_dict, dict_file)\n",
        "dict_file.close()"
      ],
      "metadata": {
        "id": "Bq_odyEPT-V-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=50\n",
        "dataset=[]\n",
        "\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "        #cv2.imshow('LIVE',img)\n",
        "        #cv2.waitKey(100)\n",
        "        try:\n",
        "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "            #Coverting the image into gray scale\n",
        "            resized=cv2.resize(gray,(img_size,img_size))\n",
        "            #resizing the gray scale into 50x50, since we need a fixed common size for all the images in the dataset\n",
        "            dataset.append([resized,label_dict[category]])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ],
      "metadata": {
        "id": "FvuKDwaFtMlC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f-LbzRrtPhF",
        "outputId": "0942b998-b6e8-45ea-d43d-98ebcd2baa05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3874"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "shuffle(dataset)"
      ],
      "metadata": {
        "id": "mahDNf5StR_z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "target=[]\n",
        "\n",
        "for feature,label in dataset:\n",
        "    data.append(feature)\n",
        "    target.append(label)"
      ],
      "metadata": {
        "id": "QlFDcxb2tSDI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
        "target=np.array(target)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "new_target = to_categorical(target)"
      ],
      "metadata": {
        "id": "TPON7rnMtU2M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/EG505P/data.npy',data)\n",
        "np.save('/content/drive/MyDrive/EG505P/target.npy',new_target)"
      ],
      "metadata": {
        "id": "yPTYPARItU5p"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}